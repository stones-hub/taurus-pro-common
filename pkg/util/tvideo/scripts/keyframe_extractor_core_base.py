"""
å…³é”®å¸§æå–æ ¸å¿ƒå®ç°
python keyframe_extractor_core.py --out ./keyframes --max-frames 300 --mode smart --time-interval 1.0 demo.mp4
"""

import os
import cv2
import time
import json
import logging
import numpy as np

logger = logging.getLogger(__name__)


# æ™ºèƒ½æå–é…ç½®å¸¸é‡ï¼ˆä¸å†å²å®ç°ä¿æŒä¸€è‡´ï¼‰
SMART_EXTRACTION_CONFIG = {
    'SCENE_CHANGE_THRESHOLD': 35.0,
    'MIN_INTERVAL': 0.5,
    'MAX_INTERVAL': 3.0,
    'HIST_WEIGHT': 0.3,
    'SSIM_WEIGHT': 0.3,
    'EDGE_WEIGHT': 0.3,
    'MOTION_WEIGHT': 0.1,
    'QUALITY_WEIGHT': 0.4,
    'CHANGE_WEIGHT': 0.6,
    'QUALITY_THRESHOLD': 20.0,
}


def _monitor_performance(func):
    def wrapper(*args, **kwargs):
        start_time = time.time()
        video_path = args[0] if args else kwargs.get('video_path')
        try:
            result = func(*args, **kwargs)
            duration = time.time() - start_time
            keyframe_count = len(result) if result else 0
            logger.info(f"å…³é”®å¸§æå–æˆåŠŸ: {video_path}, è€—æ—¶: {duration:.2f}s, æå–æ•°é‡: {keyframe_count}")
            return result
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"âŒ å…³é”®å¸§æå–å¤±è´¥: {video_path}, è€—æ—¶: {duration:.2f}s, é”™è¯¯: {e}")
            raise
    return wrapper


def extract_keyframes_with_fallback(video_path, output_dir, max_frames=200, method='smart', time_interval=None, progress_callback=None):
    try:
        return extract_keyframes(video_path, output_dir, max_frames, method, time_interval=time_interval, progress_callback=progress_callback)
    except Exception as e:
        logger.warning(f"æ™ºèƒ½æå–å¤±è´¥: {e}, é™çº§åˆ°é—´éš”æå–")
        try:
            return extract_keyframes(video_path, output_dir, max_frames, 'interval', time_interval=time_interval, progress_callback=progress_callback)
        except Exception as e2:
            logger.error(f"é—´éš”æå–ä¹Ÿå¤±è´¥: {e2}, ä½¿ç”¨æœ€å°æå–")
            return _extract_minimal_keyframes(video_path, output_dir, max_frames)


def _extract_minimal_keyframes(video_path, output_dir, max_frames):
    try:
        os.makedirs(output_dir, exist_ok=True)
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return []
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        keyframe_paths = []
        frame_indices = []
        if max_frames >= 1:
            frame_indices.append(0)
        if max_frames >= 2:
            frame_indices.append(total_frames - 1)
        if max_frames >= 3:
            frame_indices.append(total_frames // 2)
        if max_frames > 3:
            interval = total_frames // max_frames
            for i in range(1, max_frames - 2):
                idx = i * interval
                if idx not in frame_indices and idx < total_frames:
                    frame_indices.append(idx)
        frame_indices = sorted(set(frame_indices))[:max_frames]
        for i, frame_idx in enumerate(frame_indices):
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            if ret:
                timestamp = frame_idx / fps if fps > 0 else frame_idx
                filename = f"keyframe_{i:03d}_{timestamp:.2f}s.jpg"
                filepath = os.path.join(output_dir, filename)
                resized_frame = _resize_to_480p(frame)
                cv2.imwrite(filepath, resized_frame, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
                keyframe_paths.append(filepath)
        cap.release()
        logger.info(f"æœ€å°æå–å®Œæˆ: {len(keyframe_paths)}å¸§")
        return keyframe_paths
    except Exception as e:
        logger.error(f"æœ€å°æå–å¤±è´¥: {e}")
        return []


@_monitor_performance
def extract_keyframes(video_path, output_dir, max_frames=200, method='smart', time_interval=None, progress_callback=None):
    try:
        os.makedirs(output_dir, exist_ok=True)
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise Exception(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        duration = total_frames / fps
        def send_log(message):
            if progress_callback:
                progress_callback({'log_message': message})
            logger.info(message)
        send_log(
            f"è§†é¢‘æ–‡ä»¶åˆ†æ: æ€»å¸§æ•°={total_frames}, å¸§ç‡={fps:.2f}FPS, æ—¶é•¿={duration:.2f}ç§’({duration//60:.0f}åˆ†{duration%60:.0f}ç§’), ç†è®ºå¯†åº¦={total_frames/duration:.1f}å¸§/ç§’"
            if duration > 0 else f"è§†é¢‘æ–‡ä»¶åˆ†æ: æ€»å¸§æ•°={total_frames}, å¸§ç‡={fps:.2f}FPS"
        )
        if method == 'smart':
            send_log("é€‰æ‹©æ™ºèƒ½æå–æ¨¡å¼")
            keyframe_paths = _extract_smart_keyframes(cap, output_dir, max_frames, time_interval=time_interval, progress_callback=progress_callback)
        elif method == 'uniform':
            send_log("é€‰æ‹©å‡åŒ€åˆ†å¸ƒæå–æ¨¡å¼")
            send_log("æå–ç­–ç•¥: ç­‰é—´éš”æ—¶é—´åˆ†å¸ƒ")
            keyframe_paths = _extract_uniform_keyframes(cap, output_dir, max_frames, total_frames)
        else:
            send_log("é€‰æ‹©æ—¶é—´é—´éš”æå–æ¨¡å¼")
            seconds_interval = None
            if duration > 300:
                computed_interval = duration / 300.0
                if time_interval is not None:
                    seconds_interval = max(float(time_interval), computed_interval)
                else:
                    seconds_interval = computed_interval
            else:
                if time_interval is not None:
                    seconds_interval = float(time_interval)
                else:
                    seconds_interval = duration / max_frames if max_frames > 0 else 1.0
            if fps and fps > 0:
                interval_frames = max(1, int(round(seconds_interval * fps)))
            else:
                interval_frames = max(1, total_frames // max_frames) if max_frames > 0 else 1
            keyframe_paths = _extract_interval_keyframes(cap, output_dir, interval_frames, max_frames)
        cap.release()
        send_log("å…³é”®å¸§æå–ä»»åŠ¡å®Œæˆ!")
        send_log(f"   - æˆåŠŸæå–: {len(keyframe_paths)}å¸§")
        send_log(f"   - æ–‡ä»¶åˆ—è¡¨: {[os.path.basename(p) for p in keyframe_paths[:5]]}" + ("..." if len(keyframe_paths) > 5 else ""))
        return keyframe_paths
    except Exception as e:
        logger.error(f"å…³é”®å¸§æå–å¤±è´¥: {e}")
        return []


def _calculate_scene_change_score(frame1, frame2):
    try:
        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)
        hist1 = cv2.calcHist([frame1], [0, 1, 2], None, [32, 32, 32], [0, 256, 0, 256, 0, 256])
        hist2 = cv2.calcHist([frame2], [0, 1, 2], None, [32, 32, 32], [0, 256, 0, 256, 0, 256])
        hist_corr = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
        hist_score = (1 - max(0, hist_corr)) * 100
        mu1 = cv2.GaussianBlur(gray1.astype(np.float32), (5, 5), 1.0)
        mu2 = cv2.GaussianBlur(gray2.astype(np.float32), (5, 5), 1.0)
        mu1_sq = mu1 * mu1
        mu2_sq = mu2 * mu2
        mu1_mu2 = mu1 * mu2
        sigma1_sq = cv2.GaussianBlur(gray1.astype(np.float32) * gray1, (5, 5), 1.0) - mu1_sq
        sigma2_sq = cv2.GaussianBlur(gray2.astype(np.float32) * gray2, (5, 5), 1.0) - mu2_sq
        sigma12 = cv2.GaussianBlur(gray1.astype(np.float32) * gray2, (5, 5), 1.0) - mu1_mu2
        c1, c2 = (0.01 * 255) ** 2, (0.03 * 255) ** 2
        ssim_map = ((2 * mu1_mu2 + c1) * (2 * sigma12 + c2)) / ((mu1_sq + mu2_sq + c1) * (sigma1_sq + sigma2_sq + c2))
        ssim_score = (1 - np.mean(ssim_map)) * 100
        edges1 = cv2.Canny(gray1, 50, 150)
        edges2 = cv2.Canny(gray2, 50, 150)
        edge_diff = cv2.absdiff(edges1, edges2)
        edge_change_score = np.mean(edge_diff) * 2
        frame_diff = cv2.absdiff(gray1, gray2)
        motion_score = np.mean(frame_diff)
        config = SMART_EXTRACTION_CONFIG
        change_score = (
            hist_score * config['HIST_WEIGHT'] +
            ssim_score * config['SSIM_WEIGHT'] +
            edge_change_score * config['EDGE_WEIGHT'] +
            motion_score * config['MOTION_WEIGHT']
        )
        return min(100.0, max(0.0, change_score))
    except Exception:
        try:
            gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)
            diff = cv2.absdiff(gray1, gray2)
            return np.mean(diff)
        except Exception:
            return 0.0


def _calculate_frame_quality(frame):
    try:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        quality_score = laplacian_var * 0.7 + edge_density * 1000 * 0.3
        return quality_score
    except Exception:
        return 50.0


def _calculate_comprehensive_score(frame, prev_frame=None):
    config = SMART_EXTRACTION_CONFIG
    quality_score = _calculate_frame_quality(frame)
    normalized_quality = min(100.0, quality_score / 5.0)
    change_score = 0
    if prev_frame is not None:
        change_score = _calculate_scene_change_score(prev_frame, frame)
    total_score = (
        normalized_quality * config['QUALITY_WEIGHT'] +
        change_score * config['CHANGE_WEIGHT']
    )
    return total_score, normalized_quality, change_score


def _is_dark_frame(frame, threshold=35):
    try:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        mean_brightness = np.mean(gray)
        dark_ratio = np.sum(gray < threshold) / gray.size
        brightness_std = np.std(gray)
        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
        hist = hist / hist.sum()
        entropy = -np.sum(hist * np.log2(hist + 1e-7))
        is_dark = (
            mean_brightness < threshold or
            dark_ratio > 0.95 or
            (brightness_std < 10 and entropy < 3.0)
        )
        return is_dark
    except Exception:
        return False


def _check_frame_similarity(frame1_gray, frame2_gray, threshold=0.75):
    try:
        hist1 = cv2.calcHist([frame1_gray], [0], None, [32], [0, 256])
        hist2 = cv2.calcHist([frame2_gray], [0], None, [32], [0, 256])
        hist_similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
        small1 = cv2.resize(frame1_gray, (32, 32))
        small2 = cv2.resize(frame2_gray, (32, 32))
        template_similarity = cv2.matchTemplate(small1, small2, cv2.TM_CCOEFF_NORMED)[0][0]
        similarity = 0.5 * hist_similarity + 0.5 * template_similarity
        return similarity > threshold
    except Exception:
        return False


def _resize_to_480p(frame):
    try:
        h, w = frame.shape[:2]
        if h == 0 or w == 0:
            return frame
        target_h = 720
        if h == target_h:
            return frame
        scale = target_h / float(h)
        new_w = max(1, int(round(w * scale)))
        resized = cv2.resize(frame, (new_w, target_h), interpolation=cv2.INTER_AREA)
        return resized
    except Exception:
        return frame


def _extract_content_driven_keyframes(cap, output_dir, max_frames, progress_callback=None):
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = total_frames / fps if fps > 0 else 0
    def send_log(message):
        if progress_callback:
            progress_callback({'log_message': message})
        logger.info(message)
    send_log("=== å†…å®¹é©±åŠ¨å…³é”®å¸§æå–æ¨¡å¼ ===")
    send_log(
        f"è§†é¢‘ä¿¡æ¯: æ€»å¸§æ•°={total_frames}, å¸§ç‡={fps:.2f}FPS, æ—¶é•¿={duration:.2f}ç§’({duration//60:.0f}åˆ†{duration%60:.0f}ç§’), ç†è®ºå¯†åº¦={total_frames/duration:.1f}å¸§/ç§’"
        if duration > 0 else f"è§†é¢‘ä¿¡æ¯: æ€»å¸§æ•°={total_frames}, å¸§ç‡={fps:.2f}FPS"
    )
    config = SMART_EXTRACTION_CONFIG
    min_interval = config['MIN_INTERVAL']
    max_interval = config['MAX_INTERVAL']
    scene_change_threshold = config['SCENE_CHANGE_THRESHOLD']
    send_log(f"æå–å‚æ•°: æœ€å°é—´éš”={min_interval}ç§’, æœ€å¤§é—´éš”={max_interval}ç§’, åœºæ™¯å˜åŒ–é˜ˆå€¼={scene_change_threshold}, æœ€å¤§å…³é”®å¸§æ•°={max_frames}")
    send_log("ä¼˜åŒ–ç­–ç•¥: è‡ªé€‚åº”æ­¥é•¿ + åœºæ™¯å˜åŒ–æ£€æµ‹ + è´¨é‡è¯„ä¼°")
    keyframe_paths = []
    last_saved_frame = None
    last_saved_timestamp = -1
    current_time = 0.0
    adaptive_step = 0.5
    skipped_dark = 0
    skipped_similar = 0
    last_report_time = 0
    used_filenames = set()
    send_log("å¼€å§‹é€å¸§åˆ†æ...")
    active_second = 0
    has_active_second = False
    best_second_frame = None
    best_second_timestamp = None
    best_second_score = -1.0
    best_second_quality = 0.0
    best_second_change = 0.0
    def commit_best_of_second():
        nonlocal best_second_frame, best_second_timestamp, best_second_score
        nonlocal best_second_quality, best_second_change
        nonlocal last_saved_frame, last_saved_timestamp
        nonlocal keyframe_paths, used_filenames, adaptive_step
        if best_second_frame is None or best_second_timestamp is None:
            return
        if last_saved_frame is not None:
            try:
                current_gray = cv2.cvtColor(best_second_frame, cv2.COLOR_BGR2GRAY)
                last_gray = cv2.cvtColor(last_saved_frame, cv2.COLOR_BGR2GRAY)
                if _check_frame_similarity(last_gray, current_gray, threshold=0.8):
                    return
            except Exception:
                pass
        base_filename = f"keyframe_{len(keyframe_paths):03d}_{best_second_timestamp:.2f}s.jpg"
        filename = base_filename
        counter = 1
        while filename in used_filenames:
            name_part = base_filename.replace('.jpg', '')
            filename = f"{name_part}_v{counter}.jpg"
            counter += 1
        used_filenames.add(filename)
        filepath = os.path.join(output_dir, filename)
        resized_frame = _resize_to_480p(best_second_frame)
        cv2.imwrite(filepath, resized_frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
        keyframe_paths.append(filepath)
        last_saved_frame = best_second_frame.copy()
        last_saved_timestamp = best_second_timestamp
        send_log(f"ä¿å­˜å…³é”®å¸§: {filename} | ç»¼åˆå¾—åˆ†={best_second_score:.1f} | å›¾åƒè´¨é‡={best_second_quality:.1f}")
        if progress_callback:
            try:
                file_size = os.path.getsize(filepath) if os.path.exists(filepath) else 0
                height, width = best_second_frame.shape[:2]
                progress_callback({
                    'coverage': min(1.0, best_second_timestamp / duration) if duration > 0 else 0.0,
                    'elapsed_seconds': float(best_second_timestamp),
                    'duration_seconds': float(duration),
                    'saved_frames': int(len(keyframe_paths)),
                    'max_frames': int(max_frames),
                    'new_frame_path': filepath,
                    'new_frame_timestamp': float(best_second_timestamp),
                    'change_score': float(best_second_change),
                    'quality_score': float(best_second_quality),
                    'width': int(width),
                    'height': int(height),
                    'file_size': int(file_size)
                })
            except Exception:
                pass
        if best_second_change > scene_change_threshold:
            adaptive_step = min_interval
        else:
            adaptive_step = min(max_interval, adaptive_step * 1.5)
        best_second_frame = None
        best_second_timestamp = None
        best_second_score = -1.0
        best_second_quality = 0.0
        best_second_change = 0.0
    while current_time < duration and len(keyframe_paths) < max_frames:
        if current_time - last_report_time >= 10:
            last_report_time = current_time
            progress = (current_time / duration) * 100 if duration > 0 else 0
            send_log(f"è¿›åº¦ {progress:.1f}% | å·²æå– {len(keyframe_paths)} å¸§ | å½“å‰æ—¶é—´ {current_time:.1f}s")
            import gc
            gc.collect()
        cur_sec = int(current_time)
        if not has_active_second:
            active_second = cur_sec
            has_active_second = True
        elif cur_sec != active_second:
            if len(keyframe_paths) < max_frames:
                commit_best_of_second()
            active_second = cur_sec
        frame_idx = int(current_time * fps)
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if not ret:
            current_time += adaptive_step
            continue
        if _is_dark_frame(frame):
            skipped_dark += 1
            if skipped_dark % 10 == 1:
                send_log(f"è·³è¿‡é»‘å±å¸§: æ—¶é—´{current_time:.2f}s (äº®åº¦è¿‡ä½)")
            current_time += adaptive_step
            continue
        total_score, quality_score, change_score = _calculate_comprehensive_score(frame, last_saved_frame)
        if total_score > best_second_score:
            best_second_frame = frame.copy()
            best_second_timestamp = current_time
            best_second_score = total_score
            best_second_quality = quality_score
            best_second_change = change_score
        if change_score > scene_change_threshold:
            adaptive_step = min_interval
        else:
            adaptive_step = min(max_interval, adaptive_step * 1.2)
        current_time += adaptive_step
    if len(keyframe_paths) < max_frames:
        commit_best_of_second()
    send_log(f"å†…å®¹é©±åŠ¨æå–å®Œæˆ: æœ€ç»ˆä¿å­˜={len(keyframe_paths)}å¸§, è·³è¿‡é»‘å±å¸§={skipped_dark}å¸§, è·³è¿‡ç›¸ä¼¼å¸§={skipped_similar}å¸§, è¦†ç›–æ—¶é•¿={min(current_time, duration):.2f}ç§’" + (f", å¹³å‡é—´éš”={duration/len(keyframe_paths):.2f}ç§’/å¸§" if len(keyframe_paths) > 0 else ""))
    return keyframe_paths


def _extract_smart_keyframes(cap, output_dir, max_frames, time_interval=None, progress_callback=None):
    start_time = time.time()
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = total_frames / fps if fps > 0 else 0
    logger.info(f"\n=== ä¼˜åŒ–æ™ºèƒ½å…³é”®å¸§æå– ===")
    logger.info(f"è§†é¢‘ä¿¡æ¯: FPS={fps:.2f}, æ€»å¸§æ•°={total_frames}, æ—¶é•¿={duration:.2f}ç§’")
    logger.info(f"ç›®æ ‡å¸§æ•°: {max_frames}")
    if duration <= 120:
        logger.info(f"ç­–ç•¥é€‰æ‹©: çŸ­è§†é¢‘å†…å®¹é©±åŠ¨æ¨¡å¼ (æ—¶é•¿â‰¤2åˆ†é’Ÿ)")
    else:
        logger.info(f"ç­–ç•¥é€‰æ‹©: é•¿è§†é¢‘å†…å®¹é©±åŠ¨æ¨¡å¼ (æ—¶é•¿>2åˆ†é’Ÿ)")
    logger.info(f"æå–ç­–ç•¥: ä»…å†…å®¹é©±åŠ¨ï¼ŒæŒ‰ç§’èšåˆå–æœ€ä½³å¸§ï¼ˆæ¯ç§’ä¸€å¸§ï¼‰")
    keyframe_paths = _extract_content_driven_keyframes(cap, output_dir, max_frames, progress_callback)
    processing_time = time.time() - start_time
    logger.info(f"\næ™ºèƒ½æå–æ€»ç»“:")
    logger.info(f"   - æœ€ç»ˆå¸§æ•°: {len(keyframe_paths)}å¸§")
    logger.info(f"   - å¤„ç†è€—æ—¶: {processing_time:.2f}ç§’")
    logger.info(f"   - æå–æ•ˆç‡: {len(keyframe_paths)/processing_time:.1f}å¸§/ç§’" if processing_time > 0 else "   - æå–æ•ˆç‡: N/A")
    logger.info(f"   - è¦†ç›–å¯†åº¦: {len(keyframe_paths)/duration:.2f}å¸§/ç§’" if duration > 0 else "   - è¦†ç›–å¯†åº¦: N/A")
    return keyframe_paths


def _extract_uniform_keyframes(cap, output_dir, max_frames, total_frames, include_cover=True, start_index=0, used_filenames=None):
    keyframe_paths = []
    interval = max(1, total_frames // max_frames)
    if used_filenames is None:
        used_filenames = set()
    for i in range(max_frames):
        frame_idx = i * interval
        if not include_cover and frame_idx == 0:
            frame_idx += max(1, interval)
        if frame_idx >= total_frames:
            break
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if ret:
            timestamp = frame_idx / cap.get(cv2.CAP_PROP_FPS)
            base_filename = f"keyframe_{start_index + i:03d}_{timestamp:.2f}s.jpg"
            filename = base_filename
            counter = 1
            while filename in used_filenames:
                name_part = base_filename.replace('.jpg', '')
                filename = f"{name_part}_v{counter}.jpg"
                counter += 1
            used_filenames.add(filename)
            filepath = os.path.join(output_dir, filename)
            out = _resize_to_480p(frame)
            cv2.imwrite(filepath, out, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
            keyframe_paths.append(filepath)
    return keyframe_paths


def _extract_interval_keyframes(cap, output_dir, interval, max_frames):
    keyframe_paths = []
    frame_idx = 0
    saved_count = 0
    while saved_count < max_frames:
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if not ret:
            break
        timestamp = frame_idx / cap.get(cv2.CAP_PROP_FPS)
        filename = f"keyframe_{saved_count:03d}_{timestamp:.2f}s.jpg"
        filepath = os.path.join(output_dir, filename)
        out = _resize_to_480p(frame)
        cv2.imwrite(filepath, out, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
        keyframe_paths.append(filepath)
        frame_idx += interval
        saved_count += 1
    return keyframe_paths


def debug_keyframe_extraction(video_path, output_dir, max_frames=200, method='smart'):
    debug_info = {
        'video_info': {},
        'extraction_params': {},
        'keyframes': [],
        'performance': {}
    }
    start_time = time.time()
    try:
        cap = cv2.VideoCapture(video_path)
        if cap.isOpened():
            debug_info['video_info'] = {
                'fps': cap.get(cv2.CAP_PROP_FPS),
                'total_frames': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),
                'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
                'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
                'duration': cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)
            }
            cap.release()
        debug_info['extraction_params'] = {
            'method': method,
            'max_frames': max_frames,
            'change_threshold': SMART_EXTRACTION_CONFIG['SCENE_CHANGE_THRESHOLD'],
            'quality_threshold': SMART_EXTRACTION_CONFIG['QUALITY_THRESHOLD'],
        }
        keyframes = extract_keyframes(video_path, output_dir, max_frames, method)
        processing_time = time.time() - start_time
        debug_info['performance'] = {
            'processing_time': processing_time,
            'total_keyframes': len(keyframes),
            'fps_performance': len(keyframes) / processing_time if processing_time > 0 else 0
        }
        debug_filename = f'debug_keyframes_{int(time.time())}.json'
        debug_filepath = os.path.join(output_dir, debug_filename)
        with open(debug_filepath, 'w', encoding='utf-8') as f:
            json.dump(debug_info, f, indent=2, ensure_ascii=False)
        logger.info(f"ğŸ” è°ƒè¯•ä¿¡æ¯å·²ä¿å­˜: {debug_filepath}")
        return keyframes, debug_info
    except Exception as e:
        debug_info['error'] = str(e)
        logger.error(f"è°ƒè¯•æ¨¡å¼æå–å¤±è´¥: {e}")
        return [], debug_info


def get_video_info(video_path):
    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return None
        info = {
            'total_frames': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),
            'fps': cap.get(cv2.CAP_PROP_FPS),
            'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
            'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
        }
        info['duration'] = info['total_frames'] / info['fps'] if info['fps'] > 0 else 0
        cap.release()
        return info
    except Exception as e:
        logger.error(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
        return None


if __name__ == '__main__':
    # è½»é‡å‘½ä»¤è¡Œå…¥å£ï¼šæ”¯æŒç›´æ¥ä¼ å…¥æœ¬åœ°mp4æ–‡ä»¶è¿›è¡Œå…³é”®å¸§æå–
    try:
        import argparse
        import sys
        import os

        parser = argparse.ArgumentParser(description='æœ¬åœ°mp4å…³é”®å¸§æå–ï¼ˆç‹¬ç«‹ï¼Œæ— éœ€Djangoï¼‰')
        parser.add_argument('video', help='æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¦‚ /path/to/video.mp4')
        parser.add_argument('--out', help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ä¸è§†é¢‘åŒç›®å½•çš„ {stem}_keyframesï¼‰')
        parser.add_argument('--max-frames', type=int, default=300, help='æœ€å¤§å…³é”®å¸§æ•°é‡ï¼Œé»˜è®¤300')
        parser.add_argument('--mode', choices=['smart', 'uniform', 'interval'], default='smart', help='æå–æ¨¡å¼ï¼Œé»˜è®¤smart')
        parser.add_argument('--time-interval', type=float, default=None, help='intervalæ¨¡å¼çš„ç§’çº§é—´éš”ï¼›æ™ºèƒ½æ¨¡å¼ä»…ä½œå‚è€ƒ')
        args = parser.parse_args()

        video_path = os.path.abspath(args.video)
        if not os.path.exists(video_path) or not os.path.isfile(video_path):
            print(f"[ERROR] æ— æ•ˆçš„è§†é¢‘æ–‡ä»¶: {video_path}", file=sys.stderr)
            sys.exit(2)

        # è®¡ç®—é»˜è®¤è¾“å‡ºç›®å½•ï¼š<video_dir>/<video_stem>_keyframes
        if args.out:
            output_dir = os.path.abspath(args.out)
        else:
            video_dir = os.path.dirname(video_path)
            video_stem = os.path.splitext(os.path.basename(video_path))[0]
            output_dir = os.path.join(video_dir, f"{video_stem}_keyframes")

        os.makedirs(output_dir, exist_ok=True)

        paths = extract_keyframes(
            video_path=video_path,
            output_dir=output_dir,
            max_frames=args.max_frames,
            method=args.mode,
            time_interval=args.time_interval,
            progress_callback=None,
        )

        if not paths:
            print("[ERROR] æœªç”Ÿæˆå…³é”®å¸§", file=sys.stderr)
            sys.exit(1)

        print(f"ç”Ÿæˆ {len(paths)} å¼ å…³é”®å¸§ â†’ {output_dir}")
        # æ‰“å°å‰5ä¸ªæ–‡ä»¶åä½œä¸ºç®€è¦è¾“å‡º
        try:
            import os as _os
            preview = [ _os.path.basename(p) for p in paths[:5] ]
            suffix = '...' if len(paths) > 5 else ''
            print(f"ç¤ºä¾‹: {preview}{suffix}")
        except Exception:
            pass
        sys.exit(0)
    except SystemExit:
        raise
    except Exception as _e:
        import traceback as _tb, sys as _sys
        _tb.print_exc()
        _sys.exit(1)


