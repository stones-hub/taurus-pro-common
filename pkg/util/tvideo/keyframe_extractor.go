package tvideo

import (
	"bufio"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"os/exec"
	"path/filepath"
	"strconv"
	"strings"
	"time"
)

// KeyframeExtractionMode å…³é”®å¸§æå–æ¨¡å¼
type KeyframeExtractionMode string

const (
	ModeSmart    KeyframeExtractionMode = "smart"    // æ™ºèƒ½æ¨¡å¼
	ModeUniform  KeyframeExtractionMode = "uniform"  // å‡åŒ€åˆ†å¸ƒæ¨¡å¼
	ModeInterval KeyframeExtractionMode = "interval" // æ—¶é—´é—´éš”æ¨¡å¼

)

// KeyframeExtractionOptions å…³é”®å¸§æå–é€‰é¡¹
type KeyframeExtractionOptions struct {
	MaxFrames        int                              `json:"max_frames"`    // æœ€å¤§å…³é”®å¸§æ•°é‡
	Mode             KeyframeExtractionMode           `json:"mode"`          // æå–æ¨¡å¼
	TimeInterval     *float64                         `json:"time_interval"` // æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
	OutputDir        string                           `json:"output_dir"`    // è¾“å‡ºç›®å½•
	EnableDebug      bool                             `json:"enable_debug"`  // æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
	ProgressCallback func(progress *KeyframeProgress) `json:"-"`             // è¿›åº¦å›è°ƒ
}

// KeyframeProgress å…³é”®å¸§æå–è¿›åº¦ä¿¡æ¯
type KeyframeProgress struct {
	Coverage          float64 `json:"coverage"`            // è¦†ç›–è¿›åº¦ (0-1)
	ElapsedSeconds    float64 `json:"elapsed_seconds"`     // å·²å¤„ç†æ—¶é—´
	DurationSeconds   float64 `json:"duration_seconds"`    // æ€»æ—¶é•¿
	SavedFrames       int     `json:"saved_frames"`        // å·²ä¿å­˜å¸§æ•°
	MaxFrames         int     `json:"max_frames"`          // æœ€å¤§å¸§æ•°
	NewFramePath      string  `json:"new_frame_path"`      // æ–°å¸§è·¯å¾„
	NewFrameTimestamp float64 `json:"new_frame_timestamp"` // æ–°å¸§æ—¶é—´æˆ³
	ChangeScore       float64 `json:"change_score"`        // å˜åŒ–å¾—åˆ†
	QualityScore      float64 `json:"quality_score"`       // è´¨é‡å¾—åˆ†
	Width             int     `json:"width"`               // å¸§å®½åº¦
	Height            int     `json:"height"`              // å¸§é«˜åº¦
	FileSize          int64   `json:"file_size"`           // æ–‡ä»¶å¤§å°
	LogMessage        string  `json:"log_message"`         // æ—¥å¿—æ¶ˆæ¯
}

// VideoInfo è§†é¢‘ä¿¡æ¯
type VideoInfo struct {
	TotalFrames int     `json:"total_frames"` // æ€»å¸§æ•°
	FPS         float64 `json:"fps"`          // å¸§ç‡
	Width       int     `json:"width"`        // å®½åº¦
	Height      int     `json:"height"`       // é«˜åº¦
	Duration    float64 `json:"duration"`     // æ—¶é•¿ï¼ˆç§’ï¼‰
}

// KeyframeExtractionResult å…³é”®å¸§æå–ç»“æœ
type KeyframeExtractionResult struct {
	KeyframePaths  []string   `json:"keyframe_paths"`  // å…³é”®å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨
	VideoInfo      *VideoInfo `json:"video_info"`      // è§†é¢‘ä¿¡æ¯
	ProcessingTime float64    `json:"processing_time"` // å¤„ç†è€—æ—¶ï¼ˆç§’ï¼‰
	ExtractionMode string     `json:"extraction_mode"` // æå–æ¨¡å¼
	TotalFrames    int        `json:"total_frames"`    // æ€»å¸§æ•°
	Success        bool       `json:"success"`         // æ˜¯å¦æˆåŠŸ
	ErrorMessage   string     `json:"error_message"`   // é”™è¯¯ä¿¡æ¯
}

// DebugInfo è°ƒè¯•ä¿¡æ¯
type DebugInfo struct {
	VideoInfo        *VideoInfo             `json:"video_info"`        // è§†é¢‘ä¿¡æ¯
	ExtractionParams map[string]interface{} `json:"extraction_params"` // æå–å‚æ•°
	Keyframes        []string               `json:"keyframes"`         // å…³é”®å¸§è·¯å¾„
	Performance      map[string]interface{} `json:"performance"`       // æ€§èƒ½ä¿¡æ¯
	SceneAnalysis    map[string]interface{} `json:"scene_analysis"`    // åœºæ™¯åˆ†æä¿¡æ¯
	QualityMetrics   map[string]interface{} `json:"quality_metrics"`   // è´¨é‡æŒ‡æ ‡ä¿¡æ¯
	ExtractionStats  map[string]interface{} `json:"extraction_stats"`  // æå–ç»Ÿè®¡ä¿¡æ¯
	Error            string                 `json:"error,omitempty"`   // é”™è¯¯ä¿¡æ¯
}

// KeyframeExtractor å…³é”®å¸§æå–å™¨
type KeyframeExtractor struct {
	PythonPath  string // Pythonå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„, å³pythonåœ°å€
	scriptPath  string // ä¸´æ—¶Pythonè„šæœ¬è·¯å¾„, å³è„šæœ¬åœ°å€
	tempDirPath string // ä¸´æ—¶æ–‡ä»¶ç›®å½•è·¯å¾„, å³ä¸´æ—¶æ–‡ä»¶å­˜å‚¨ç›®å½•
}

// KeyframeExtractorOption é…ç½®é€‰é¡¹å‡½æ•°ç±»å‹
type KeyframeExtractorOption func(*KeyframeExtractor)

// WithPythonPath è®¾ç½®Pythonè·¯å¾„
func WithPythonPath(path string) KeyframeExtractorOption {
	return func(k *KeyframeExtractor) {
		k.PythonPath = path
	}
}

// checkPythonAvailable å†…éƒ¨æ–¹æ³•ï¼Œæ£€æŸ¥Pythonç¯å¢ƒ
func (k *KeyframeExtractor) checkPythonAvailable() error {
	// æ£€æŸ¥Python
	if err := exec.Command(k.PythonPath, "--version").Run(); err != nil {
		return fmt.Errorf("pythonä¸å¯ç”¨: %v", err)
	}

	// æ£€æŸ¥å¿…è¦çš„PythonåŒ…
	cmd := exec.Command(k.PythonPath, "-c", "import cv2, numpy")
	if err := cmd.Run(); err != nil {
		return fmt.Errorf("ç¼ºå°‘å¿…è¦çš„PythonåŒ…(opencv-python, numpy): %v", err)
	}

	return nil
}

// NewKeyframeExtractor åˆ›å»ºå…³é”®å¸§æå–å™¨
func NewKeyframeExtractor(opts ...KeyframeExtractorOption) (*KeyframeExtractor, error) {
	// è®¾ç½®é»˜è®¤å€¼
	k := &KeyframeExtractor{
		PythonPath: "python3", // é»˜è®¤ä½¿ç”¨python3
	}

	// åº”ç”¨é€‰é¡¹
	for _, opt := range opts {
		opt(k)
	}

	// æ£€æŸ¥Pythonç¯å¢ƒ
	if err := k.checkPythonAvailable(); err != nil {
		return nil, fmt.Errorf("pythonç¯å¢ƒæ£€æŸ¥å¤±è´¥: %v", err)
	}

	// åˆ›å»ºä¸´æ—¶è„šæœ¬
	scriptPath, err := k.createTempScript()
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»ºä¸´æ—¶è„šæœ¬å¤±è´¥: %v", err)
	}
	k.scriptPath = scriptPath
	fmt.Printf("ä¸´æ—¶Pythonè„šæœ¬è·¯å¾„: %s\n", scriptPath)

	return k, nil
}

// Close å®ç°io.Closeræ¥å£ï¼Œç”¨äºèµ„æºæ¸…ç†,
// æ³¨æ„: éœ€è¦ç”¨æˆ·ä¸»åŠ¨æ¸…ç†
func (k *KeyframeExtractor) Close() error {
	if k.tempDirPath != "" {
		// æ¸…ç†æ•´ä¸ªä¸´æ—¶ç›®å½•
		if err := os.RemoveAll(k.tempDirPath); err != nil {
			return fmt.Errorf("æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: %v", err)
		}
		k.tempDirPath = ""
		k.scriptPath = ""
	}
	return nil
}

// ExtractKeyframes æå–å…³é”®å¸§ï¼ˆç»Ÿä¸€çš„ä¸»æ–¹æ³•ï¼‰
func (k *KeyframeExtractor) ExtractKeyframes(ctx context.Context, videoPath string, options *KeyframeExtractionOptions) (*KeyframeExtractionResult, *DebugInfo, error) {
	startTime := time.Now()

	// éªŒè¯è¾“å…¥æ–‡ä»¶
	if _, err := os.Stat(videoPath); os.IsNotExist(err) {
		return nil, nil, fmt.Errorf("è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: %s", videoPath)
	}

	// è®¾ç½®é»˜è®¤é€‰é¡¹
	if options == nil {
		options = k.CreateDefaultOptions()
		options.OutputDir = filepath.Join(filepath.Dir(videoPath), "keyframes")
	}

	// åˆ›å»ºè¾“å‡ºç›®å½•
	if err := os.MkdirAll(options.OutputDir, 0755); err != nil {
		return nil, nil, fmt.Errorf("åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: %v", err)
	}

	// æ„å»ºPythonå‘½ä»¤
	args := k.buildPythonArgs(k.scriptPath, videoPath, options)

	// æ‰§è¡ŒPythonè„šæœ¬
	cmd := exec.CommandContext(ctx, k.PythonPath, args...)

	var debugInfo *DebugInfo
	if options.EnableDebug {
		// å¦‚æœå¯ç”¨äº†è°ƒè¯•æ¨¡å¼ï¼Œå‡†å¤‡æ¥æ”¶è°ƒè¯•ä¿¡æ¯
		debugInfo = &DebugInfo{}
	}

	// å¤„ç†è¾“å‡ºå’Œè¿›åº¦
	if options.ProgressCallback != nil {
		// åˆ›å»ºç®¡é“æ¥æ•è·è¾“å‡º
		stdout, err := cmd.StdoutPipe()
		if err != nil {
			return nil, debugInfo, fmt.Errorf("åˆ›å»ºè¾“å‡ºç®¡é“å¤±è´¥: %v", err)
		}

		// å¯åŠ¨å‘½ä»¤
		if err := cmd.Start(); err != nil {
			return nil, debugInfo, fmt.Errorf("å¯åŠ¨Pythonè„šæœ¬å¤±è´¥: %v", err)
		}

		// åœ¨goroutineä¸­å¤„ç†è¾“å‡º
		go k.handlePythonOutput(stdout, options.ProgressCallback)

		// ç­‰å¾…å‘½ä»¤å®Œæˆ
		if err := cmd.Wait(); err != nil {
			return nil, debugInfo, fmt.Errorf("pythonè„šæœ¬æ‰§è¡Œå¤±è´¥: %v", err)
		}
	} else {
		// æ²¡æœ‰è¿›åº¦å›è°ƒæ—¶ï¼Œç›´æ¥æ‰§è¡Œ
		cmd.Stdout = os.Stdout
		cmd.Stderr = os.Stderr

		if err := cmd.Run(); err != nil {
			return nil, debugInfo, fmt.Errorf("pythonè„šæœ¬æ‰§è¡Œå¤±è´¥: %v", err)
		}
	}

	// è·å–å…³é”®å¸§æ–‡ä»¶åˆ—è¡¨
	keyframePaths, err := k.getKeyframePaths(options.OutputDir)
	if err != nil {
		return nil, debugInfo, fmt.Errorf("è·å–å…³é”®å¸§æ–‡ä»¶å¤±è´¥: %v", err)
	}

	// è·å–è§†é¢‘ä¿¡æ¯
	videoInfo, _ := k.GetVideoInfo(ctx, videoPath)

	// å¦‚æœå¯ç”¨äº†è°ƒè¯•æ¨¡å¼ï¼ŒåŠ è½½è°ƒè¯•ä¿¡æ¯
	if options.EnableDebug {
		debugInfo, _ = k.loadDebugInfo(options.OutputDir)
	}

	result := &KeyframeExtractionResult{
		KeyframePaths:  keyframePaths,
		VideoInfo:      videoInfo,
		ProcessingTime: time.Since(startTime).Seconds(),
		ExtractionMode: string(options.Mode),
		TotalFrames:    len(keyframePaths),
		Success:        true,
	}

	return result, debugInfo, nil
}

// GetVideoInfo è·å–è§†é¢‘ä¿¡æ¯
func (k *KeyframeExtractor) GetVideoInfo(ctx context.Context, videoPath string) (*VideoInfo, error) {
	// æ„å»ºPythonå‘½ä»¤è·å–è§†é¢‘ä¿¡æ¯
	args := []string{
		k.scriptPath,
		"--get-info",
		videoPath,
	}

	cmd := exec.CommandContext(ctx, k.PythonPath, args...)
	output, err := cmd.Output()
	if err != nil {
		return nil, fmt.Errorf("è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: %v", err)
	}

	// è§£æJSONè¾“å‡º
	var videoInfo VideoInfo
	if err := json.Unmarshal(output, &videoInfo); err != nil {
		return nil, fmt.Errorf("è§£æè§†é¢‘ä¿¡æ¯å¤±è´¥: %v", err)
	}

	return &videoInfo, nil
}

// createTempScript åˆ›å»ºä¸´æ—¶Pythonè„šæœ¬æ–‡ä»¶
func (k *KeyframeExtractor) createTempScript() (string, error) {
	// åˆ›å»ºå”¯ä¸€çš„ä¸´æ—¶ç›®å½•ï¼ˆä½¿ç”¨è¿›ç¨‹IDå’Œæ—¶é—´æˆ³ç¡®ä¿å”¯ä¸€æ€§ï¼‰
	tempDir := filepath.Join(os.TempDir(), fmt.Sprintf("keyframe_extractor_%d_%d", os.Getpid(), time.Now().UnixNano()))
	if err := os.MkdirAll(tempDir, 0755); err != nil {
		return "", fmt.Errorf("åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥: %v", err)
	}
	k.tempDirPath = tempDir

	// åˆ›å»ºä¸´æ—¶æ–‡ä»¶
	scriptPath := filepath.Join(tempDir, "extractor.py")
	file, err := os.OpenFile(scriptPath, os.O_WRONLY|os.O_CREATE|os.O_EXCL, 0644)
	if err != nil {
		os.RemoveAll(tempDir) // æ¸…ç†ä¸´æ—¶ç›®å½•
		return "", fmt.Errorf("åˆ›å»ºä¸´æ—¶è„šæœ¬æ–‡ä»¶å¤±è´¥: %v", err)
	}
	defer file.Close()

	// å†™å…¥è„šæœ¬å†…å®¹
	if _, err := file.WriteString(pythonScript); err != nil {
		os.RemoveAll(tempDir) // æ¸…ç†ä¸´æ—¶ç›®å½•
		return "", fmt.Errorf("å†™å…¥è„šæœ¬å†…å®¹å¤±è´¥: %v", err)
	}

	return scriptPath, nil
}

// buildPythonArgs æ„å»ºPythonå‘½ä»¤è¡Œå‚æ•°
func (k *KeyframeExtractor) buildPythonArgs(scriptPath string, videoPath string, options *KeyframeExtractionOptions) []string {
	args := []string{
		scriptPath,
		videoPath,
		"--out", options.OutputDir,
		"--max-frames", strconv.Itoa(options.MaxFrames),
		"--mode", string(options.Mode),
	}

	if options.TimeInterval != nil {
		args = append(args, "--time-interval", strconv.FormatFloat(*options.TimeInterval, 'f', -1, 64))
	}

	// å¦‚æœå¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œæ·»åŠ --debugå‚æ•°
	if options.EnableDebug {
		args = append(args, "--debug")
	}

	return args
}

// getKeyframePaths è·å–å…³é”®å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨
func (k *KeyframeExtractor) getKeyframePaths(outputDir string) ([]string, error) {
	// è¯»å–è¾“å‡ºç›®å½•ä¸­çš„å…³é”®å¸§æ–‡ä»¶
	entries, err := os.ReadDir(outputDir)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–è¾“å‡ºç›®å½•å¤±è´¥: %v", err)
	}

	var keyframePaths []string
	for _, entry := range entries {
		if !entry.IsDir() && strings.HasPrefix(entry.Name(), "keyframe_") && strings.HasSuffix(entry.Name(), ".jpg") {
			keyframePaths = append(keyframePaths, filepath.Join(outputDir, entry.Name()))
		}
	}

	return keyframePaths, nil
}

// loadDebugInfo åŠ è½½è°ƒè¯•ä¿¡æ¯
func (k *KeyframeExtractor) loadDebugInfo(outputDir string) (*DebugInfo, error) {
	// æŸ¥æ‰¾è°ƒè¯•æ–‡ä»¶
	entries, err := os.ReadDir(outputDir)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–è¾“å‡ºç›®å½•å¤±è´¥: %v", err)
	}

	var debugFile string
	for _, entry := range entries {
		if !entry.IsDir() && strings.HasPrefix(entry.Name(), "debug_keyframes_") && strings.HasSuffix(entry.Name(), ".json") {
			debugFile = filepath.Join(outputDir, entry.Name())
			break
		}
	}

	if debugFile == "" {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°è°ƒè¯•æ–‡ä»¶")
	}

	// è¯»å–è°ƒè¯•æ–‡ä»¶
	data, err := os.ReadFile(debugFile)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–è°ƒè¯•æ–‡ä»¶å¤±è´¥: %v", err)
	}

	// è§£æJSON
	var debugInfo DebugInfo
	if err := json.Unmarshal(data, &debugInfo); err != nil {
		return nil, fmt.Errorf("è§£æè°ƒè¯•æ–‡ä»¶å¤±è´¥: %v", err)
	}

	return &debugInfo, nil
}

// handlePythonOutput å¤„ç†Pythonè„šæœ¬çš„è¾“å‡ºï¼Œè§£æè¿›åº¦ä¿¡æ¯
func (k *KeyframeExtractor) handlePythonOutput(stdout io.ReadCloser, progressCallback func(progress *KeyframeProgress)) {
	defer stdout.Close()

	// ä½¿ç”¨æ›´å¤§çš„bufferæ¥è¯»å–è¾“å‡º
	reader := bufio.NewReaderSize(stdout, 64*1024)

	for {
		// è¯»å–ä¸€è¡Œï¼ŒåŒ…æ‹¬åˆ†éš”ç¬¦
		line, err := reader.ReadString('\n')
		if err != nil {
			if err != io.EOF {
				progressCallback(&KeyframeProgress{
					LogMessage: fmt.Sprintf("è¯»å–Pythonè¾“å‡ºæ—¶å‡ºé”™: %v", err),
				})
			}
			break
		}

		// å¤„ç†è¿™ä¸€è¡Œ
		line = strings.TrimSpace(line)
		if line == "" {
			continue
		}

		// å°è¯•è§£æJSONæ ¼å¼çš„è¿›åº¦ä¿¡æ¯
		var progress KeyframeProgress
		if err := json.Unmarshal([]byte(line), &progress); err == nil {
			// æˆåŠŸè§£æä¸ºè¿›åº¦ä¿¡æ¯ï¼Œè°ƒç”¨å›è°ƒ
			progressCallback(&progress)
		} else {
			// ä¸æ˜¯JSONæ ¼å¼ï¼Œå¯èƒ½æ˜¯æ™®é€šæ—¥å¿—ï¼Œä¹Ÿé€šè¿‡å›è°ƒä¼ é€’
			progressCallback(&KeyframeProgress{
				LogMessage: line,
			})
		}
	}
}

// GetSupportedModes è·å–æ”¯æŒçš„æå–æ¨¡å¼
func (k *KeyframeExtractor) GetSupportedModes() []KeyframeExtractionMode {
	return []KeyframeExtractionMode{
		ModeSmart,
		ModeUniform,
		ModeInterval,
	}
}

// CreateDefaultOptions åˆ›å»ºé»˜è®¤é€‰é¡¹
func (k *KeyframeExtractor) CreateDefaultOptions() *KeyframeExtractionOptions {
	return &KeyframeExtractionOptions{
		MaxFrames:   300,
		Mode:        ModeSmart,
		EnableDebug: false,
	}
}

// CreatePresetOptions åˆ›å»ºé¢„è®¾é€‰é¡¹
func (k *KeyframeExtractor) CreatePresetOptions(preset string) *KeyframeExtractionOptions {
	switch preset {
	case "fast":
		// å¿«é€Ÿæå–ï¼šè¾ƒå°‘å¸§æ•°ï¼Œå‡åŒ€åˆ†å¸ƒ
		return &KeyframeExtractionOptions{
			MaxFrames:   100,
			Mode:        ModeUniform,
			EnableDebug: false,
		}
	case "quality":
		// è´¨é‡ä¼˜å…ˆï¼šæ™ºèƒ½æå–ï¼Œè¾ƒå¤šå¸§æ•°
		return &KeyframeExtractionOptions{
			MaxFrames:   500,
			Mode:        ModeSmart,
			EnableDebug: true,
		}
	case "interval":
		// é—´éš”æå–ï¼šå›ºå®šæ—¶é—´é—´éš”
		interval := 5.0 // 5ç§’é—´éš”
		return &KeyframeExtractionOptions{
			MaxFrames:    300,
			Mode:         ModeInterval,
			TimeInterval: &interval,
			EnableDebug:  false,
		}
	default:
		// é»˜è®¤é…ç½®
		return k.CreateDefaultOptions()
	}
}

const (
	// åµŒå…¥çš„Pythonè„šæœ¬å†…å®¹
	pythonScript = `"""
å…³é”®å¸§æå–æ ¸å¿ƒå®ç°
python keyframe_extractor_core.py --out ./keyframes --max-frames 300 --mode smart --time-interval 1.0 demo.mp4
"""

import os
import cv2
import time
import json
import logging
import numpy as np

logger = logging.getLogger(__name__)


# æ™ºèƒ½æå–é…ç½®å¸¸é‡ï¼ˆä¸å†å²å®ç°ä¿æŒä¸€è‡´ï¼‰
SMART_EXTRACTION_CONFIG = {
    'SCENE_CHANGE_THRESHOLD': 35.0,
    'MIN_INTERVAL': 0.5,
    'MAX_INTERVAL': 3.0,
    'HIST_WEIGHT': 0.3,
    'SSIM_WEIGHT': 0.3,
    'EDGE_WEIGHT': 0.3,
    'MOTION_WEIGHT': 0.1,
    'QUALITY_WEIGHT': 0.4,
    'CHANGE_WEIGHT': 0.6,
    'QUALITY_THRESHOLD': 20.0,
}


def _monitor_performance(func):
    def wrapper(*args, **kwargs):
        start_time = time.time()
        video_path = args[0] if args else kwargs.get('video_path')
        try:
            result = func(*args, **kwargs)
            duration = time.time() - start_time
            keyframe_count = len(result) if result else 0
            logger.info(f"å…³é”®å¸§æå–æˆåŠŸ: {video_path}, è€—æ—¶: {duration:.2f}s, æå–æ•°é‡: {keyframe_count}")
            return result
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"âŒ å…³é”®å¸§æå–å¤±è´¥: {video_path}, è€—æ—¶: {duration:.2f}s, é”™è¯¯: {e}")
            raise
    return wrapper


def extract_keyframes_with_fallback(video_path, output_dir, max_frames=200, method='smart', time_interval=None, progress_callback=None):
    try:
        return extract_keyframes(video_path, output_dir, max_frames, method, time_interval=time_interval, progress_callback=progress_callback)
    except Exception as e:
        logger.warning(f"æ™ºèƒ½æå–å¤±è´¥: {e}, é™çº§åˆ°é—´éš”æå–")
        try:
            return extract_keyframes(video_path, output_dir, max_frames, 'interval', time_interval=time_interval, progress_callback=progress_callback)
        except Exception as e2:
            logger.error(f"é—´éš”æå–ä¹Ÿå¤±è´¥: {e2}, ä½¿ç”¨æœ€å°æå–")
            return _extract_minimal_keyframes(video_path, output_dir, max_frames)


def _extract_minimal_keyframes(video_path, output_dir, max_frames):
    try:
        os.makedirs(output_dir, exist_ok=True)
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return []
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        keyframe_paths = []
        frame_indices = []
        if max_frames >= 1:
            frame_indices.append(0)
        if max_frames >= 2:
            frame_indices.append(total_frames - 1)
        if max_frames >= 3:
            frame_indices.append(total_frames // 2)
        if max_frames > 3:
            interval = total_frames // max_frames
            for i in range(1, max_frames - 2):
                idx = i * interval
                if idx not in frame_indices and idx < total_frames:
                    frame_indices.append(idx)
        frame_indices = sorted(set(frame_indices))[:max_frames]
        for i, frame_idx in enumerate(frame_indices):
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            if ret:
                timestamp = frame_idx / fps if fps > 0 else frame_idx
                filename = f"keyframe_{i:03d}_{timestamp:.2f}s.jpg"
                filepath = os.path.join(output_dir, filename)
                resized_frame = _resize_to_480p(frame)
                cv2.imwrite(filepath, resized_frame, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
                keyframe_paths.append(filepath)
        cap.release()
        logger.info(f"æœ€å°æå–å®Œæˆ: {len(keyframe_paths)}å¸§")
        return keyframe_paths
    except Exception as e:
        logger.error(f"æœ€å°æå–å¤±è´¥: {e}")
        return []


@_monitor_performance
def extract_keyframes(video_path, output_dir, max_frames=200, method='smart', time_interval=None, progress_callback=None):
    try:
        os.makedirs(output_dir, exist_ok=True)
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise Exception(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        duration = total_frames / fps
        
        # ç›´æ¥æ‰“å°è¿›åº¦ä¿¡æ¯åˆ°æ ‡å‡†è¾“å‡º
        def print_progress(progress_data):
            import json
            import sys
            print(json.dumps(progress_data), flush=True)
            sys.stdout.flush()
            
        def send_log(message):
            print_progress({'log_message': message})
            logger.info(message)
            
        send_log(
            f"è§†é¢‘æ–‡ä»¶åˆ†æ: æ€»å¸§æ•°={total_frames}, å¸§ç‡={fps:.2f}FPS, æ—¶é•¿={duration:.2f}ç§’({duration//60:.0f}åˆ†{duration%60:.0f}ç§’), ç†è®ºå¯†åº¦={total_frames/duration:.1f}å¸§/ç§’"
            if duration > 0 else f"è§†é¢‘æ–‡ä»¶åˆ†æ: æ€»å¸§æ•°={total_frames}, å¸§ç‡={fps:.2f}FPS"
        )
        if method == 'smart':
            send_log("é€‰æ‹©æ™ºèƒ½æå–æ¨¡å¼")
            keyframe_paths = _extract_smart_keyframes(cap, output_dir, max_frames, time_interval=time_interval, progress_callback=progress_callback)
        elif method == 'uniform':
            send_log("é€‰æ‹©å‡åŒ€åˆ†å¸ƒæå–æ¨¡å¼")
            send_log("æå–ç­–ç•¥: ç­‰é—´éš”æ—¶é—´åˆ†å¸ƒ")
            keyframe_paths = _extract_uniform_keyframes(cap, output_dir, max_frames, total_frames)
        else:
            send_log("é€‰æ‹©æ—¶é—´é—´éš”æå–æ¨¡å¼")
            seconds_interval = None
            if duration > 300:
                computed_interval = duration / 300.0
                if time_interval is not None:
                    seconds_interval = max(float(time_interval), computed_interval)
                else:
                    seconds_interval = computed_interval
            else:
                if time_interval is not None:
                    seconds_interval = float(time_interval)
                else:
                    seconds_interval = duration / max_frames if max_frames > 0 else 1.0
            if fps and fps > 0:
                interval_frames = max(1, int(round(seconds_interval * fps)))
            else:
                interval_frames = max(1, total_frames // max_frames) if max_frames > 0 else 1
            keyframe_paths = _extract_interval_keyframes(cap, output_dir, interval_frames, max_frames)
        cap.release()
        send_log("å…³é”®å¸§æå–ä»»åŠ¡å®Œæˆ!")
        send_log(f"   - æˆåŠŸæå–: {len(keyframe_paths)}å¸§")
        send_log(f"   - æ–‡ä»¶åˆ—è¡¨: {[os.path.basename(p) for p in keyframe_paths[:5]]}" + ("..." if len(keyframe_paths) > 5 else ""))
        return keyframe_paths
    except Exception as e:
        logger.error(f"å…³é”®å¸§æå–å¤±è´¥: {e}")
        return []


def _calculate_scene_change_score(frame1, frame2):
    try:
        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)
        hist1 = cv2.calcHist([frame1], [0, 1, 2], None, [32, 32, 32], [0, 256, 0, 256, 0, 256])
        hist2 = cv2.calcHist([frame2], [0, 1, 2], None, [32, 32, 32], [0, 256, 0, 256, 0, 256])
        hist_corr = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
        hist_score = (1 - max(0, hist_corr)) * 100
        mu1 = cv2.GaussianBlur(gray1.astype(np.float32), (5, 5), 1.0)
        mu2 = cv2.GaussianBlur(gray2.astype(np.float32), (5, 5), 1.0)
        mu1_sq = mu1 * mu1
        mu2_sq = mu2 * mu2
        mu1_mu2 = mu1 * mu2
        sigma1_sq = cv2.GaussianBlur(gray1.astype(np.float32) * gray1, (5, 5), 1.0) - mu1_sq
        sigma2_sq = cv2.GaussianBlur(gray2.astype(np.float32) * gray2, (5, 5), 1.0) - mu2_sq
        sigma12 = cv2.GaussianBlur(gray1.astype(np.float32) * gray2, (5, 5), 1.0) - mu1_mu2
        c1, c2 = (0.01 * 255) ** 2, (0.03 * 255) ** 2
        ssim_map = ((2 * mu1_mu2 + c1) * (2 * sigma12 + c2)) / ((mu1_sq + mu2_sq + c1) * (sigma1_sq + sigma2_sq + c2))
        ssim_score = (1 - np.mean(ssim_map)) * 100
        edges1 = cv2.Canny(gray1, 50, 150)
        edges2 = cv2.Canny(gray2, 50, 150)
        edge_diff = cv2.absdiff(edges1, edges2)
        edge_change_score = np.mean(edge_diff) * 2
        frame_diff = cv2.absdiff(gray1, gray2)
        motion_score = np.mean(frame_diff)
        config = SMART_EXTRACTION_CONFIG
        change_score = (
            hist_score * config['HIST_WEIGHT'] +
            ssim_score * config['SSIM_WEIGHT'] +
            edge_change_score * config['EDGE_WEIGHT'] +
            motion_score * config['MOTION_WEIGHT']
        )
        return min(100.0, max(0.0, change_score))
    except Exception:
        try:
            gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)
            diff = cv2.absdiff(gray1, gray2)
            return np.mean(diff)
        except Exception:
            return 0.0


def _calculate_frame_quality(frame):
    try:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        quality_score = laplacian_var * 0.7 + edge_density * 1000 * 0.3
        return quality_score
    except Exception:
        return 50.0


def _calculate_comprehensive_score(frame, prev_frame=None):
    config = SMART_EXTRACTION_CONFIG
    quality_score = _calculate_frame_quality(frame)
    normalized_quality = min(100.0, quality_score / 5.0)
    change_score = 0
    if prev_frame is not None:
        change_score = _calculate_scene_change_score(prev_frame, frame)
    total_score = (
        normalized_quality * config['QUALITY_WEIGHT'] +
        change_score * config['CHANGE_WEIGHT']
    )
    return total_score, normalized_quality, change_score


def _is_dark_frame(frame, threshold=35):
    try:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        mean_brightness = np.mean(gray)
        dark_ratio = np.sum(gray < threshold) / gray.size
        brightness_std = np.std(gray)
        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
        hist = hist / hist.sum()
        entropy = -np.sum(hist * np.log2(hist + 1e-7))
        is_dark = (
            mean_brightness < threshold or
            dark_ratio > 0.95 or
            (brightness_std < 10 and entropy < 3.0)
        )
        return is_dark
    except Exception:
        return False


def _check_frame_similarity(frame1_gray, frame2_gray, threshold=0.75):
    try:
        hist1 = cv2.calcHist([frame1_gray], [0], None, [32], [0, 256])
        hist2 = cv2.calcHist([frame2_gray], [0], None, [32], [0, 256])
        hist_similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
        small1 = cv2.resize(frame1_gray, (32, 32))
        small2 = cv2.resize(frame2_gray, (32, 32))
        template_similarity = cv2.matchTemplate(small1, small2, cv2.TM_CCOEFF_NORMED)[0][0]
        similarity = 0.5 * hist_similarity + 0.5 * template_similarity
        return similarity > threshold
    except Exception:
        return False


def _resize_to_480p(frame):
    try:
        h, w = frame.shape[:2]
        if h == 0 or w == 0:
            return frame
        target_h = 720
        if h == target_h:
            return frame
        scale = target_h / float(h)
        new_w = max(1, int(round(w * scale)))
        resized = cv2.resize(frame, (new_w, target_h), interpolation=cv2.INTER_AREA)
        return resized
    except Exception:
        return frame


def _extract_content_driven_keyframes(cap, output_dir, max_frames, progress_callback=None):
    import json
    import sys
    import os
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = total_frames / fps if fps > 0 else 0
    keyframe_paths = []  # åˆå§‹åŒ–å…³é”®å¸§è·¯å¾„åˆ—è¡¨
    
    def send_progress(current_time, message=None, frame_info=None):
        if not progress_callback:
            return
            
        # åªåœ¨ä¿å­˜å…³é”®å¸§æ—¶å‘é€è¿›åº¦ä¿¡æ¯
        if frame_info:
            progress = {
                'coverage': min(1.0, current_time / duration) if duration > 0 else 0.0,
                'elapsed_seconds': float(current_time),
                'duration_seconds': float(duration),
                'saved_frames': len(keyframe_paths),
                'max_frames': int(max_frames),
                'new_frame_path': frame_info.get('new_frame_path', ''),
                'new_frame_timestamp': float(frame_info.get('new_frame_timestamp', 0)),
                'change_score': float(frame_info.get('change_score', 0)),
                'quality_score': float(frame_info.get('quality_score', 0)),
                'width': int(frame_info.get('width', 0)),
                'height': int(frame_info.get('height', 0)),
                'file_size': int(frame_info.get('file_size', 0)),
                'log_message': frame_info.get('log_message', '')
            }
            print(json.dumps(progress), flush=True)
            sys.stdout.flush()
        elif message:  # åªå‘é€æ—¥å¿—æ¶ˆæ¯
            progress = {
                'coverage': 0.0,
                'elapsed_seconds': 0.0,
                'duration_seconds': float(duration),
                'saved_frames': len(keyframe_paths),
                'max_frames': int(max_frames),
                'new_frame_path': '',
                'new_frame_timestamp': 0.0,
                'change_score': 0.0,
                'quality_score': 0.0,
                'width': 0,
                'height': 0,
                'file_size': 0,
                'log_message': message
            }
            print(json.dumps(progress), flush=True)
            sys.stdout.flush()
        
    def send_log(message):
        send_progress(0, message=message)
    send_log("=== å†…å®¹é©±åŠ¨å…³é”®å¸§æå–æ¨¡å¼ ===")
    send_log(
        f"è§†é¢‘ä¿¡æ¯: æ€»å¸§æ•°={total_frames}, å¸§ç‡={fps:.2f}FPS, æ—¶é•¿={duration:.2f}ç§’({duration//60:.0f}åˆ†{duration%60:.0f}ç§’), ç†è®ºå¯†åº¦={total_frames/duration:.1f}å¸§/ç§’"
        if duration > 0 else f"è§†é¢‘ä¿¡æ¯: æ€»å¸§æ•°={total_frames}, å¸§ç‡={fps:.2f}FPS"
    )
    config = SMART_EXTRACTION_CONFIG
    min_interval = config['MIN_INTERVAL']
    max_interval = config['MAX_INTERVAL']
    scene_change_threshold = config['SCENE_CHANGE_THRESHOLD']
    send_log(f"æå–å‚æ•°: æœ€å°é—´éš”={min_interval}ç§’, æœ€å¤§é—´éš”={max_interval}ç§’, åœºæ™¯å˜åŒ–é˜ˆå€¼={scene_change_threshold}, æœ€å¤§å…³é”®å¸§æ•°={max_frames}")
    send_log("ä¼˜åŒ–ç­–ç•¥: è‡ªé€‚åº”æ­¥é•¿ + åœºæ™¯å˜åŒ–æ£€æµ‹ + è´¨é‡è¯„ä¼°")
    keyframe_paths = []
    last_saved_frame = None
    last_saved_timestamp = -1
    current_time = 0.0
    adaptive_step = 0.5
    skipped_dark = 0
    skipped_similar = 0
    last_report_time = 0
    used_filenames = set()
    send_log("å¼€å§‹é€å¸§åˆ†æ...")
    active_second = 0
    has_active_second = False
    best_second_frame = None
    best_second_timestamp = None
    best_second_score = -1.0
    best_second_quality = 0.0
    best_second_change = 0.0
    def commit_best_of_second():
        nonlocal best_second_frame, best_second_timestamp, best_second_score
        nonlocal best_second_quality, best_second_change
        nonlocal last_saved_frame, last_saved_timestamp
        nonlocal keyframe_paths, used_filenames, adaptive_step
        if best_second_frame is None or best_second_timestamp is None:
            return
            
        # å‘é€å¤„ç†è¿›åº¦
        send_progress(best_second_timestamp)
        
        if last_saved_frame is not None:
            try:
                current_gray = cv2.cvtColor(best_second_frame, cv2.COLOR_BGR2GRAY)
                last_gray = cv2.cvtColor(last_saved_frame, cv2.COLOR_BGR2GRAY)
                if _check_frame_similarity(last_gray, current_gray, threshold=0.8):
                    return
            except Exception:
                pass
        base_filename = f"keyframe_{len(keyframe_paths):03d}_{best_second_timestamp:.2f}s.jpg"
        filename = base_filename
        counter = 1
        while filename in used_filenames:
            name_part = base_filename.replace('.jpg', '')
            filename = f"{name_part}_v{counter}.jpg"
            counter += 1
        used_filenames.add(filename)
        filepath = os.path.join(output_dir, filename)
        resized_frame = _resize_to_480p(best_second_frame)
        cv2.imwrite(filepath, resized_frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
        keyframe_paths.append(filepath)
        last_saved_frame = best_second_frame.copy()
        last_saved_timestamp = best_second_timestamp
        
        # è·å–å¸§ä¿¡æ¯
        try:
            file_size = os.path.getsize(filepath) if os.path.exists(filepath) else 0
            height, width = best_second_frame.shape[:2]
            frame_info = {
                'saved_frames': int(len(keyframe_paths)),
                'new_frame_path': filepath,
                'new_frame_timestamp': float(best_second_timestamp),
                'change_score': float(best_second_change),
                'quality_score': float(best_second_quality),
                'width': int(width),
                'height': int(height),
                'file_size': int(file_size)
            }
            
            # å‘é€è¿›åº¦å’Œå¸§ä¿¡æ¯
            send_progress(best_second_timestamp, 
                message=f"ä¿å­˜å…³é”®å¸§: {filename} | ç»¼åˆå¾—åˆ†={best_second_score:.1f} | å›¾åƒè´¨é‡={best_second_quality:.1f}",
                frame_info=frame_info)
                
        except Exception as e:
            send_log(f"å¤„ç†å¸§ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        if best_second_change > scene_change_threshold:
            adaptive_step = min_interval
        else:
            adaptive_step = min(max_interval, adaptive_step * 1.5)
        best_second_frame = None
        best_second_timestamp = None
        best_second_score = -1.0
        best_second_quality = 0.0
        best_second_change = 0.0
    while current_time < duration and len(keyframe_paths) < max_frames:
        # æ¯ç§’å‘é€ä¸€æ¬¡è¿›åº¦æ›´æ–°
        if current_time - last_report_time >= 1:
            last_report_time = current_time
            progress = (current_time / duration) * 100 if duration > 0 else 0
            send_progress(current_time, 
                message=f"è¿›åº¦ {progress:.1f}% | å·²æå– {len(keyframe_paths)} å¸§ | å½“å‰æ—¶é—´ {current_time:.1f}s")
            
            # æ¯10ç§’åšä¸€æ¬¡åƒåœ¾å›æ”¶
            if current_time % 10 == 0:
                import gc
                gc.collect()
        cur_sec = int(current_time)
        if not has_active_second:
            active_second = cur_sec
            has_active_second = True
        elif cur_sec != active_second:
            if len(keyframe_paths) < max_frames:
                commit_best_of_second()
            active_second = cur_sec
        frame_idx = int(current_time * fps)
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if not ret:
            # å‘é€è¿›åº¦æ›´æ–°ï¼ˆå³ä½¿è¯»å–å¤±è´¥ï¼‰
            send_progress(current_time, message=f"è·³è¿‡å¸§ {frame_idx} (è¯»å–å¤±è´¥)")
            current_time += adaptive_step
            continue
            
        # ä¸å†æ¯ç§’å‘é€è¿›åº¦æ›´æ–°ï¼Œåªåœ¨ä¿å­˜å…³é”®å¸§æ—¶å‘é€
        if _is_dark_frame(frame):
            skipped_dark += 1
            if skipped_dark % 10 == 1:
                send_log(f"è·³è¿‡é»‘å±å¸§: æ—¶é—´{current_time:.2f}s (äº®åº¦è¿‡ä½)")
            current_time += adaptive_step
            continue
        total_score, quality_score, change_score = _calculate_comprehensive_score(frame, last_saved_frame)
        if total_score > best_second_score:
            best_second_frame = frame.copy()
            best_second_timestamp = current_time
            best_second_score = total_score
            best_second_quality = quality_score
            best_second_change = change_score
        if change_score > scene_change_threshold:
            adaptive_step = min_interval
        else:
            adaptive_step = min(max_interval, adaptive_step * 1.2)
        current_time += adaptive_step
    if len(keyframe_paths) < max_frames:
        commit_best_of_second()
    send_log(f"å†…å®¹é©±åŠ¨æå–å®Œæˆ: æœ€ç»ˆä¿å­˜={len(keyframe_paths)}å¸§, è·³è¿‡é»‘å±å¸§={skipped_dark}å¸§, è·³è¿‡ç›¸ä¼¼å¸§={skipped_similar}å¸§, è¦†ç›–æ—¶é•¿={min(current_time, duration):.2f}ç§’" + (f", å¹³å‡é—´éš”={duration/len(keyframe_paths):.2f}ç§’/å¸§" if len(keyframe_paths) > 0 else ""))
    return keyframe_paths


def _extract_smart_keyframes(cap, output_dir, max_frames, time_interval=None, progress_callback=None):
    start_time = time.time()
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    duration = total_frames / fps if fps > 0 else 0
    
    # ç›´æ¥æ‰“å°è¿›åº¦ä¿¡æ¯åˆ°æ ‡å‡†è¾“å‡º
    def print_progress(progress_data):
        import json
        import sys
        print(json.dumps(progress_data), flush=True)
        sys.stdout.flush()
    
    def send_log(message):
        print_progress({'log_message': message})
        logger.info(message)
    
    send_log("=== ä¼˜åŒ–æ™ºèƒ½å…³é”®å¸§æå– ===")
    send_log(f"è§†é¢‘ä¿¡æ¯: FPS={fps:.2f}, æ€»å¸§æ•°={total_frames}, æ—¶é•¿={duration:.2f}ç§’")
    send_log(f"ç›®æ ‡å¸§æ•°: {max_frames}")
    
    if duration <= 120:
        send_log("ç­–ç•¥é€‰æ‹©: çŸ­è§†é¢‘å†…å®¹é©±åŠ¨æ¨¡å¼ (æ—¶é•¿â‰¤2åˆ†é’Ÿ)")
    else:
        send_log("ç­–ç•¥é€‰æ‹©: é•¿è§†é¢‘å†…å®¹é©±åŠ¨æ¨¡å¼ (æ—¶é•¿>2åˆ†é’Ÿ)")
    
    send_log("æå–ç­–ç•¥: ä»…å†…å®¹é©±åŠ¨ï¼ŒæŒ‰ç§’èšåˆå–æœ€ä½³å¸§ï¼ˆæ¯ç§’ä¸€å¸§ï¼‰")
    
    # ä½¿ç”¨ä¿®æ”¹åçš„print_progressä½œä¸ºå›è°ƒ
    keyframe_paths = _extract_content_driven_keyframes(cap, output_dir, max_frames, print_progress)
    
    processing_time = time.time() - start_time
    send_log("\næ™ºèƒ½æå–æ€»ç»“:")
    send_log(f"   - æœ€ç»ˆå¸§æ•°: {len(keyframe_paths)}å¸§")
    send_log(f"   - å¤„ç†è€—æ—¶: {processing_time:.2f}ç§’")
    send_log(f"   - æå–æ•ˆç‡: {len(keyframe_paths)/processing_time:.1f}å¸§/ç§’" if processing_time > 0 else "   - æå–æ•ˆç‡: N/A")
    send_log(f"   - è¦†ç›–å¯†åº¦: {len(keyframe_paths)/duration:.2f}å¸§/ç§’" if duration > 0 else "   - è¦†ç›–å¯†åº¦: N/A")
    
    return keyframe_paths


def _extract_uniform_keyframes(cap, output_dir, max_frames, total_frames, include_cover=True, start_index=0, used_filenames=None):
    keyframe_paths = []
    interval = max(1, total_frames // max_frames)
    if used_filenames is None:
        used_filenames = set()
    for i in range(max_frames):
        frame_idx = i * interval
        if not include_cover and frame_idx == 0:
            frame_idx += max(1, interval)
        if frame_idx >= total_frames:
            break
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if ret:
            timestamp = frame_idx / cap.get(cv2.CAP_PROP_FPS)
            base_filename = f"keyframe_{start_index + i:03d}_{timestamp:.2f}s.jpg"
            filename = base_filename
            counter = 1
            while filename in used_filenames:
                name_part = base_filename.replace('.jpg', '')
                filename = f"{name_part}_v{counter}.jpg"
                counter += 1
            used_filenames.add(filename)
            filepath = os.path.join(output_dir, filename)
            out = _resize_to_480p(frame)
            cv2.imwrite(filepath, out, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
            keyframe_paths.append(filepath)
    return keyframe_paths


def _extract_interval_keyframes(cap, output_dir, interval, max_frames):
    keyframe_paths = []
    frame_idx = 0
    saved_count = 0
    while saved_count < max_frames:
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if not ret:
            break
        timestamp = frame_idx / cap.get(cv2.CAP_PROP_FPS)
        filename = f"keyframe_{saved_count:03d}_{timestamp:.2f}s.jpg"
        filepath = os.path.join(output_dir, filename)
        out = _resize_to_480p(frame)
        cv2.imwrite(filepath, out, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
        keyframe_paths.append(filepath)
        frame_idx += interval
        saved_count += 1
    return keyframe_paths


def debug_keyframe_extraction(video_path, output_dir, max_frames=200, method='smart'):
    debug_info = {
        'video_info': {},
        'extraction_params': {},
        'keyframes': [],
        'performance': {},
        'scene_analysis': {
            'change_scores': {
                'min': 999999.0,  # ä½¿ç”¨ä¸€ä¸ªè¶³å¤Ÿå¤§çš„æ•°å­—ä»£æ›¿infinity
                'max': 0.0,
                'avg': 0.0,
                'std': 0.0,
                'scores': []  # å­˜å‚¨æ‰€æœ‰å¾—åˆ†ç”¨äºè®¡ç®—
            },
            'scene_changes': [],
            'frame_selection_reasons': []
        },
        'quality_metrics': {
            'clarity_scores': {
                'min': 999999.0,
                'max': 0.0,
                'avg': 0.0,
                'scores': []
            },
            'brightness_stats': {
                'min': 999999.0,
                'max': 0.0,
                'avg': 0.0,
                'values': []
            },
            'blur_detection': [],
            'frame_quality_scores': []
        },
        'extraction_stats': {
            'adaptive_steps': [],
            'skipped_frames': {
                'dark_frames': 0,
                'similar_frames': 0,
                'low_quality_frames': 0
            },
            'frame_intervals': [],
            'processing_stages': []
        }
    }
    
    # æ·»åŠ å¤„ç†é˜¶æ®µè®°å½•å‡½æ•°
    def add_processing_stage(stage, details):
        debug_info['extraction_stats']['processing_stages'].append({
            'stage': stage,
            'time': time.time(),
            'details': details
        })
    
    # æ›´æ–°åœºæ™¯åˆ†ææ•°æ®
    def update_scene_analysis(frame_idx, change_score, reason):
        scores = debug_info['scene_analysis']['change_scores']
        scores['min'] = min(scores['min'], change_score)
        scores['max'] = max(scores['max'], change_score)
        scores['scores'].append(change_score)
        
        if change_score > SMART_EXTRACTION_CONFIG['SCENE_CHANGE_THRESHOLD']:
            debug_info['scene_analysis']['scene_changes'].append({
                'frame': frame_idx,
                'score': change_score,
                'time': frame_idx / cap.get(cv2.CAP_PROP_FPS)
            })
        
        debug_info['scene_analysis']['frame_selection_reasons'].append({
            'frame': frame_idx,
            'reason': reason,
            'change_score': change_score
        })
    
    # æ›´æ–°è´¨é‡æŒ‡æ ‡æ•°æ®
    def update_quality_metrics(frame):
        # è®¡ç®—äº®åº¦
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        brightness = np.mean(gray)
        debug_info['quality_metrics']['brightness_stats']['values'].append(brightness)
        debug_info['quality_metrics']['brightness_stats']['min'] = min(
            debug_info['quality_metrics']['brightness_stats']['min'], 
            brightness
        )
        debug_info['quality_metrics']['brightness_stats']['max'] = max(
            debug_info['quality_metrics']['brightness_stats']['max'], 
            brightness
        )
        
        # è®¡ç®—æ¸…æ™°åº¦
        clarity = cv2.Laplacian(gray, cv2.CV_64F).var()
        debug_info['quality_metrics']['clarity_scores']['scores'].append(clarity)
        debug_info['quality_metrics']['clarity_scores']['min'] = min(
            debug_info['quality_metrics']['clarity_scores']['min'], 
            clarity
        )
        debug_info['quality_metrics']['clarity_scores']['max'] = max(
            debug_info['quality_metrics']['clarity_scores']['max'], 
            clarity
        )
        
        # æ¨¡ç³Šæ£€æµ‹
        is_blurry = clarity < 100  # è®¾ç½®ä¸€ä¸ªé˜ˆå€¼
        debug_info['quality_metrics']['blur_detection'].append({
            'frame': len(debug_info['quality_metrics']['blur_detection']),
            'is_blurry': is_blurry,
            'clarity_score': clarity
        })
    
    # åœ¨å¤„ç†ç»“æŸæ—¶è®¡ç®—å¹³å‡å€¼å’Œæ ‡å‡†å·®
    def finalize_debug_info():
        # è®¡ç®—åœºæ™¯å˜åŒ–å¾—åˆ†çš„ç»Ÿè®¡ä¿¡æ¯
        scores = debug_info['scene_analysis']['change_scores']['scores']
        if scores:
            debug_info['scene_analysis']['change_scores']['avg'] = np.mean(scores)
            debug_info['scene_analysis']['change_scores']['std'] = np.std(scores)
        
        # è®¡ç®—æ¸…æ™°åº¦å¾—åˆ†çš„å¹³å‡å€¼
        clarity_scores = debug_info['quality_metrics']['clarity_scores']['scores']
        if clarity_scores:
            debug_info['quality_metrics']['clarity_scores']['avg'] = np.mean(clarity_scores)
        
        # è®¡ç®—äº®åº¦çš„å¹³å‡å€¼
        brightness_values = debug_info['quality_metrics']['brightness_stats']['values']
        if brightness_values:
            debug_info['quality_metrics']['brightness_stats']['avg'] = np.mean(brightness_values)
        
        # æ¸…ç†ä¸­é—´æ•°æ®
        debug_info['scene_analysis']['change_scores'].pop('scores', None)
        debug_info['quality_metrics']['clarity_scores'].pop('scores', None)
        debug_info['quality_metrics']['brightness_stats'].pop('values', None)
        
        # å¦‚æœminå€¼ä»ç„¶æ˜¯åˆå§‹å€¼ï¼Œè®¾ç½®ä¸º0
        if debug_info['scene_analysis']['change_scores']['min'] == 999999.0:
            debug_info['scene_analysis']['change_scores']['min'] = 0.0
        if debug_info['quality_metrics']['clarity_scores']['min'] == 999999.0:
            debug_info['quality_metrics']['clarity_scores']['min'] = 0.0
        if debug_info['quality_metrics']['brightness_stats']['min'] == 999999.0:
            debug_info['quality_metrics']['brightness_stats']['min'] = 0.0
    start_time = time.time()
    try:
        cap = cv2.VideoCapture(video_path)
        if cap.isOpened():
            debug_info['video_info'] = {
                'fps': cap.get(cv2.CAP_PROP_FPS),
                'total_frames': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),
                'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
                'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
                'duration': cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)
            }
            cap.release()
        debug_info['extraction_params'] = {
            'method': method,
            'max_frames': max_frames,
            'change_threshold': SMART_EXTRACTION_CONFIG['SCENE_CHANGE_THRESHOLD'],
            'quality_threshold': SMART_EXTRACTION_CONFIG['QUALITY_THRESHOLD'],
        }
        keyframes = extract_keyframes(video_path, output_dir, max_frames, method)
        processing_time = time.time() - start_time
        debug_info['performance'] = {
            'processing_time': processing_time,
            'total_keyframes': len(keyframes),
            'fps_performance': len(keyframes) / processing_time if processing_time > 0 else 0
        }
        debug_filename = f'debug_keyframes_{int(time.time())}.json'
        debug_filepath = os.path.join(output_dir, debug_filename)
        with open(debug_filepath, 'w', encoding='utf-8') as f:
            json.dump(debug_info, f, indent=2, ensure_ascii=False)
        logger.info(f"ğŸ” è°ƒè¯•ä¿¡æ¯å·²ä¿å­˜: {debug_filepath}")
        return keyframes, debug_info
    except Exception as e:
        debug_info['error'] = str(e)
        logger.error(f"è°ƒè¯•æ¨¡å¼æå–å¤±è´¥: {e}")
        return [], debug_info


def get_video_info(video_path):
    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return None
        info = {
            'total_frames': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),
            'fps': cap.get(cv2.CAP_PROP_FPS),
            'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
            'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
        }
        info['duration'] = info['total_frames'] / info['fps'] if info['fps'] > 0 else 0
        cap.release()
        return info
    except Exception as e:
        logger.error(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
        return None


if __name__ == '__main__':
    # è½»é‡å‘½ä»¤è¡Œå…¥å£ï¼šæ”¯æŒç›´æ¥ä¼ å…¥æœ¬åœ°mp4æ–‡ä»¶è¿›è¡Œå…³é”®å¸§æå–
    try:
        import argparse
        import sys
        import os

        parser = argparse.ArgumentParser(description='æœ¬åœ°mp4å…³é”®å¸§æå–ï¼ˆç‹¬ç«‹ï¼Œæ— éœ€Djangoï¼‰')
        parser.add_argument('video', nargs='?', help='æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¦‚ /path/to/video.mp4')
        parser.add_argument('--out', help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ä¸è§†é¢‘åŒç›®å½•çš„ {stem}_keyframesï¼‰')
        parser.add_argument('--max-frames', type=int, default=300, help='æœ€å¤§å…³é”®å¸§æ•°é‡ï¼Œé»˜è®¤300')
        parser.add_argument('--mode', choices=['smart', 'uniform', 'interval'], default='smart', help='æå–æ¨¡å¼ï¼Œé»˜è®¤smart')
        parser.add_argument('--time-interval', type=float, default=None, help='intervalæ¨¡å¼çš„ç§’çº§é—´éš”ï¼›æ™ºèƒ½æ¨¡å¼ä»…ä½œå‚è€ƒ')
        parser.add_argument('--get-info', action='store_true', help='ä»…è·å–è§†é¢‘ä¿¡æ¯ï¼Œä¸æå–å…³é”®å¸§')
        parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œç”Ÿæˆè°ƒè¯•ä¿¡æ¯æ–‡ä»¶')
        args = parser.parse_args()

        # å¦‚æœåªæ˜¯è·å–è§†é¢‘ä¿¡æ¯
        if args.get_info:
            if not args.video:
                print("[ERROR] éœ€è¦æŒ‡å®šè§†é¢‘æ–‡ä»¶è·¯å¾„", file=sys.stderr)
                sys.exit(2)
            
            video_path = os.path.abspath(args.video)
            if not os.path.exists(video_path) or not os.path.isfile(video_path):
                print(f"[ERROR] æ— æ•ˆçš„è§†é¢‘æ–‡ä»¶: {video_path}", file=sys.stderr)
                sys.exit(2)
            
            video_info = get_video_info(video_path)
            if video_info:
                import json
                print(json.dumps(video_info, indent=2))
                sys.exit(0)
            else:
                print("[ERROR] æ— æ³•è·å–è§†é¢‘ä¿¡æ¯", file=sys.stderr)
                sys.exit(1)

        video_path = os.path.abspath(args.video)
        if not os.path.exists(video_path) or not os.path.isfile(video_path):
            print(f"[ERROR] æ— æ•ˆçš„è§†é¢‘æ–‡ä»¶: {video_path}", file=sys.stderr)
            sys.exit(2)

        # è®¡ç®—é»˜è®¤è¾“å‡ºç›®å½•ï¼š<video_dir>/<video_stem>_keyframes
        if args.out:
            output_dir = os.path.abspath(args.out)
        else:
            video_dir = os.path.dirname(video_path)
            video_stem = os.path.splitext(os.path.basename(video_path))[0]
            output_dir = os.path.join(video_dir, f"{video_stem}_keyframes")

        os.makedirs(output_dir, exist_ok=True)

        # æ ¹æ®æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼é€‰æ‹©ä¸åŒçš„æå–æ–¹æ³•
        if args.debug:
            paths, debug_info = debug_keyframe_extraction(
                video_path=video_path,
                output_dir=output_dir,
                max_frames=args.max_frames,
                method=args.mode
            )
        else:
            paths = extract_keyframes(
                video_path=video_path,
                output_dir=output_dir,
                max_frames=args.max_frames,
                method=args.mode,
                time_interval=args.time_interval,
                progress_callback=None,
            )

        if not paths:
            print("[ERROR] æœªç”Ÿæˆå…³é”®å¸§", file=sys.stderr)
            sys.exit(1)

        print(f"ç”Ÿæˆ {len(paths)} å¼ å…³é”®å¸§ â†’ {output_dir}")
        # æ‰“å°å‰5ä¸ªæ–‡ä»¶åä½œä¸ºç®€è¦è¾“å‡º
        try:
            import os as _os
            preview = [ _os.path.basename(p) for p in paths[:5] ]
            suffix = '...' if len(paths) > 5 else ''
            print(f"ç¤ºä¾‹: {preview}{suffix}")
        except Exception:
            pass
        sys.exit(0)
    except SystemExit:
        raise
    except Exception as _e:
        import traceback as _tb, sys as _sys
        _tb.print_exc()
        _sys.exit(1)


`
)
